#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®éªŒåŠ¨ç‰©è´¨é‡åˆæ ¼è¯ï¼šäºŒç»´ç è§£æ -> æ‰“å¼€URL -> æŠ“å–é¡µé¢å­—æ®µ -> å¯¼å‡ºExcel
ä¸€ä½“åŒ–è„šæœ¬ï¼ˆè‡ªåŠ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ + å®‰è£…ä¾èµ– + å®‰è£… Playwright æµè§ˆå™¨ï¼‰

ç”¨æ³•ï¼š
1) åŒå‡»/è¿è¡Œï¼š
   python cert_tool_allinone.py
   -> å¼¹çª—é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ª PDF/å›¾ç‰‡ï¼Œå¯¼å‡º Excel

2) â€œæ‹–æ‹½æ–‡ä»¶åˆ°è„šæœ¬ä¸Šâ€ï¼ˆWindows/macOS å¸¸è§ï¼‰æˆ–å‘½ä»¤è¡Œä¼ å‚ï¼š
   python cert_tool_allinone.py æ–‡ä»¶1.pdf æ–‡ä»¶2.jpg
   -> è‡ªåŠ¨æ‰¹å¤„ç†å¹¶å¯¼å‡º Excelï¼ˆé»˜è®¤è¾“å‡ºåˆ°å½“å‰ç›®å½•ï¼‰
"""

import os
import re
import sys
import time
import subprocess
import traceback
import warnings
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional

# å®‰è£…/å¯åŠ¨è¿‡ç¨‹çš„è¯¦ç»†æ—¥å¿—ï¼ˆé™é»˜æ¨¡å¼ä¸‹å†™å…¥æ­¤æ–‡ä»¶ï¼‰
SETUP_LOG_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".cert_tool_setup.log")

# å°½é‡å‡å°‘å¯åŠ¨æ—¶çš„å™ªå£°æç¤ºï¼ˆä¾‹å¦‚ SyntaxWarning ç­‰ï¼‰
warnings.filterwarnings("ignore", category=SyntaxWarning)

# å¼€å¯è°ƒè¯•è¾“å‡ºï¼šexport CERT_TOOL_DEBUG=1
DEBUG_MODE = os.environ.get("CERT_TOOL_DEBUG", "").strip() == "1"


# =========================
# 0) è™šæ‹Ÿç¯å¢ƒä¸ä¾èµ–è‡ªä¸¾
# =========================

VENV_DIRNAME = ".venv_cert"
PLAYWRIGHT_MARK = ".playwright_browsers_installed"

REQUIRED_PACKAGES = [
    "pandas",
    "openpyxl",
    "pillow",
    "opencv-python",
    "pymupdf",
    "playwright",
    "beautifulsoup4",
    "lxml",
]

# ä½ å¦‚æœå¸Œæœ›å›ºå®šç‰ˆæœ¬ï¼Œå¯æ”¹ä¸ºå¦‚ "pandas==2.2.2" è¿™ç§å½¢å¼


def is_in_venv() -> bool:
    # åœ¨ venv å†…ï¼šsys.prefix != sys.base_prefix
    return getattr(sys, "base_prefix", sys.prefix) != sys.prefix


def venv_python_path(venv_dir: str) -> str:
    if os.name == "nt":
        return os.path.join(venv_dir, "Scripts", "python.exe")
    return os.path.join(venv_dir, "bin", "python")


def run_cmd(
    cmd: List[str],
    cwd: Optional[str] = None,
    quiet: bool = False,
    progress_label: Optional[str] = None,
    log_path: Optional[str] = None,
) -> None:
    """è¿è¡Œå­å‘½ä»¤ã€‚

    quiet=True æ—¶ï¼šä¸è¾“å‡ºå‘½ä»¤ä¸å­è¿›ç¨‹è¾“å‡ºï¼ˆå†™å…¥ log_pathï¼‰ï¼Œç»ˆç«¯ä»…æ˜¾ç¤ºä¸€è¡Œè¿›åº¦åŠ¨ç”»ã€‚
    """
    if not quiet:
        subprocess.check_call(cmd, cwd=cwd)
        return

    if log_path is None:
        log_path = SETUP_LOG_PATH

    spinner = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
    label = progress_label or "â³ æ­£åœ¨åŠ è½½"

    with open(log_path, "a", encoding="utf-8") as lf:
        lf.write("\n" + "=" * 80 + "\n")
        lf.write("$ " + " ".join(cmd) + "\n")
        lf.flush()

        p = subprocess.Popen(cmd, cwd=cwd, stdout=lf, stderr=lf)
        i = 0
        last_msg_time = time.time()
        
        while True:
            ret = p.poll()
            if ret is not None:
                break
            
            # æ¯éš”3ç§’è¾“å‡ºä¸€æ¬¡"è¿˜åœ¨åŠ è½½"æç¤º
            current_time = time.time()
            if current_time - last_msg_time >= 3.0:
                sys.stdout.write("\r" + " " * (len(label) + 4) + "\r")
                sys.stdout.flush()
                print(f"  â³ {label} (è¿˜åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨å€™...)")
                last_msg_time = current_time
            
            sys.stdout.write("\r" + f"{spinner[i % len(spinner)]} {label}")
            sys.stdout.flush()
            time.sleep(0.05)  # æ›´é¢‘ç¹çš„åˆ·æ–°ï¼Œè®© spinner åŠ¨ç”»æ›´æµç•…
            i += 1

        # æ¸…ç†è¿›åº¦è¡Œ
        sys.stdout.write("\r" + " " * (len(label) + 4) + "\r")
        sys.stdout.flush()

        if ret != 0:
            raise subprocess.CalledProcessError(ret, cmd)


def ensure_venv_and_rerun() -> None:
    """
    è‹¥å½“å‰ä¸åœ¨ venv ä¸­ï¼Œåˆ™åˆ›å»º venv å¹¶ä½¿ç”¨ venv çš„ python é‡æ–°æ‰§è¡Œæœ¬è„šæœ¬ã€‚
    """
    script_dir = os.path.dirname(os.path.abspath(__file__))
    venv_dir = os.path.join(script_dir, VENV_DIRNAME)
    py_in_venv = venv_python_path(venv_dir)

    if is_in_venv():
        return

    if not os.path.exists(py_in_venv):
        import venv

        print("  â†’ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ...")
        builder = venv.EnvBuilder(with_pip=True, clear=False, upgrade=False)
        builder.create(venv_dir)
        print("  âœ“ è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»º\n")

    # ä½¿ç”¨ venv çš„ python é‡æ–°æ‰§è¡Œæœ¬è„šæœ¬ï¼ˆå¹¶æŠŠå‚æ•°åŸæ ·ä¼ é€’ï¼‰
    print("  â†’ å¯åŠ¨è™šæ‹Ÿç¯å¢ƒå¹¶åŠ è½½ä¾èµ–/æµè§ˆå™¨...\n")
    cmd = [py_in_venv, os.path.abspath(__file__)] + sys.argv[1:]
    subprocess.check_call(cmd, cwd=script_dir)
    sys.exit(0)


def pip_install(pkgs: List[str], progress_label: str = "[INFO] æ­£åœ¨å®‰è£…ä¾èµ–â€¦") -> None:
    # ä½¿ç”¨ -q é™ä½pipè¾“å‡ºå™ªå£°ï¼›è¯¦ç»†æ—¥å¿—å†™å…¥ .cert_tool_setup.log
    run_cmd(
        [sys.executable, "-m", "pip", "install", "-U", "-q"] + pkgs,
        quiet=True,
        progress_label=progress_label,
    )


def pip_install_with_progress(pkgs: List[str]) -> None:
    """é€ä¸ªå®‰è£…åŒ…å¹¶æ˜¾ç¤ºè¿›åº¦ï¼Œæ ¼å¼: ğŸ“¦ å®‰è£…ä¸­ [1/8] pandas"""
    for idx, pkg in enumerate(pkgs, 1):
        label = f"ğŸ“¦ å®‰è£…ä¸­ [{idx}/{len(pkgs)}] {pkg}"
        print(f"  {label}", end="", flush=True)
        subprocess.run(
            [sys.executable, "-m", "pip", "install", "-U", "-q", pkg],
            capture_output=True,
            check=True
        )
        print(" âœ“")



def ensure_packages_installed() -> None:
    """
    å°è¯•å¯¼å…¥æ ¸å¿ƒåº“ï¼›ç¼ºå¤±åˆ™ pip installã€‚
    """
    missing = []

    # ç”¨â€œå¯¼å…¥æ¢é’ˆâ€é¿å…è¯¯åˆ¤
    probes = {
        "pandas": "pandas",
        "openpyxl": "openpyxl",
        "pillow": "PIL",
        "opencv-python": "cv2",
        "pymupdf": "fitz",
        "playwright": "playwright",
        "beautifulsoup4": "bs4",
        "lxml": "lxml",
    }

    for pkg, mod in probes.items():
        try:
            __import__(mod)
        except Exception:
            missing.append(pkg)

    if missing:
        print(f"  â†’ æ£€æµ‹åˆ°ç¼ºå¤±åº“ï¼š{', '.join(missing)}")
        pip_install_with_progress(missing)
        print("  âœ“ ä¾èµ–åº“å·²å®‰è£…\n")

    # ç¡®ä¿ pip è‡ªèº«æ›´æ–°ï¼ˆå¯é€‰ï¼Œé™é»˜ï¼‰
    try:
        print("  â†’ æ›´æ–°å®‰è£…å·¥å…·...")
        pip_install(["pip", "setuptools", "wheel"], progress_label="ğŸ“¦ æ›´æ–°å·¥å…·ä¸­")
        print("  âœ“ å·¥å…·å·²æ›´æ–°\n")
    except Exception:
        pass


def ensure_playwright_browsers() -> None:
    """
    Playwright éœ€è¦é¢å¤–ä¸‹è½½æµè§ˆå™¨å†…æ ¸ï¼›ç”¨æ ‡è®°æ–‡ä»¶é¿å…æ¯æ¬¡éƒ½æ‰§è¡Œã€‚
    """
    script_dir = os.path.dirname(os.path.abspath(__file__))
    mark_path = os.path.join(script_dir, PLAYWRIGHT_MARK)
    if os.path.exists(mark_path):
        return

    print("  â†’ ä¸‹è½½/å®‰è£… Chromiumã€Firefoxã€WebKit æµè§ˆå™¨å¼•æ“...")
    print("     (è¿™å¯èƒ½éœ€è¦ 1-5 åˆ†é’Ÿï¼Œå–å†³äºç½‘ç»œé€Ÿåº¦)\n")
    
    browsers = ["chromium", "firefox", "webkit"]
    for idx, browser in enumerate(browsers, 1):
        label = f"ğŸŒ å®‰è£…ä¸­ [{idx}/{len(browsers)}] {browser}"
        print(f"  {label}", end="", flush=True)
        subprocess.run(
            [sys.executable, "-m", "playwright", "install", browser],
            cwd=script_dir,
            capture_output=True,
            check=True
        )
        print(" âœ“")
    
    print("  âœ“ æµè§ˆå™¨å¼•æ“å·²å®‰è£…\n")

    with open(mark_path, "w", encoding="utf-8") as f:
        f.write(str(time.time()))


# =========================
# 1) ä¸»åŠŸèƒ½ï¼šæ–‡ä»¶ -> å›¾ç‰‡
# =========================

def _pdf_first_page_to_image(pdf_path: str, dpi: int = 500):
    import fitz  # PyMuPDF
    from PIL import Image

    doc = fitz.open(pdf_path)
    page = doc.load_page(0)

    # æé«˜æ¸²æŸ“åˆ†è¾¨ç‡ï¼Œæå‡å°äºŒç»´ç è¯†åˆ«æˆåŠŸç‡ï¼ˆå¿…è¦æ—¶å¯è°ƒåˆ° 600ï¼‰
    mat = fitz.Matrix(dpi / 72.0, dpi / 72.0)
    pix = page.get_pixmap(matrix=mat, alpha=False)

    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
    doc.close()
    return img


def _image_path_to_image(img_path: str):
    from PIL import Image
    return Image.open(img_path).convert("RGB")


def file_to_image(file_path: str):

    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".pdf":
        return _pdf_first_page_to_image(file_path)
    elif ext in [".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff", ".webp"]:
        return _image_path_to_image(file_path)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}")


# =========================
# PDFè§’è½è£å‰ªæ¸²æŸ“ + QRè¯†åˆ«è¾…åŠ©ï¼ˆæå‡å°äºŒç»´ç è¯†åˆ«æˆåŠŸç‡ï¼‰
# =========================

def _pdf_render_clip_to_image(pdf_path: str, clip_rect, dpi: int = 900):
    """å°†PDFç¬¬ä¸€é¡µæŒ‡å®šåŒºåŸŸä»¥é«˜DPIæ¸²æŸ“ä¸ºå›¾ç‰‡ï¼ˆç”¨äºå°äºŒç»´ç è¯†åˆ«ï¼‰ã€‚"""
    import fitz  # PyMuPDF
    from PIL import Image

    doc = fitz.open(pdf_path)
    page = doc.load_page(0)
    mat = fitz.Matrix(dpi / 72.0, dpi / 72.0)
    pix = page.get_pixmap(matrix=mat, alpha=False, clip=clip_rect)
    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
    doc.close()
    return img


def decode_qr_from_pdf(pdf_path: str) -> List[str]:
    """ä¼˜å…ˆæ¸²æŸ“PDFè§’è½åŒºåŸŸï¼ˆé«˜DPIï¼‰æ¥è¯†åˆ«äºŒç»´ç ï¼Œå‘½ä¸­ç‡é€šå¸¸é«˜äºæ•´é¡µè¯†åˆ«ã€‚"""
    import fitz  # PyMuPDF

    doc = fitz.open(pdf_path)
    page = doc.load_page(0)
    rect = page.rect
    w, h = rect.width, rect.height

    # è§’è½è£å‰ªï¼šå…ˆå¤§åå°ï¼Œå·¦ä¸‹ä¸ºä¸»ï¼Œå³ä¸‹ä¸ºå¤‡
    clips = [
        fitz.Rect(0, h * 0.55, w * 0.45, h),
        fitz.Rect(0, h * 0.65, w * 0.35, h),
        fitz.Rect(0, h * 0.70, w * 0.30, h),
        fitz.Rect(w * 0.55, h * 0.55, w, h),
        fitz.Rect(w * 0.65, h * 0.65, w, h),
    ]
    doc.close()

    for clip in clips:
        try:
            clip_img = _pdf_render_clip_to_image(pdf_path, clip_rect=clip, dpi=900)
            qr_list = decode_qr_from_image(clip_img)
            if qr_list:
                return qr_list
        except Exception:
            pass

    return []


# =========================
# 2) å›¾åƒ -> QR å†…å®¹ï¼ˆOpenCVï¼‰
# =========================

def decode_qr_from_image(pil_img) -> List[str]:
    import cv2
    import numpy as np

    def try_decode(bgr) -> Optional[str]:
        detector = cv2.QRCodeDetector()
        data, _, _ = detector.detectAndDecode(bgr)
        if data and data.strip():
            return data.strip()
        return None

    bgr_full = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    h, w = bgr_full.shape[:2]

    # è¯ä»¶äºŒç»´ç é€šå¸¸åœ¨è§’è½ï¼šä¼˜å…ˆè£å‰ªè§’è½åŒºåŸŸï¼ˆä»å¤§åˆ°å°é€æ­¥æ”¶æ•›ï¼‰
    crops = []
    # å·¦ä¸‹è§’ï¼ˆå¸¸è§ï¼‰
    crops.append(bgr_full[int(h * 0.55):h, 0:int(w * 0.45)])
    crops.append(bgr_full[int(h * 0.65):h, 0:int(w * 0.35)])
    crops.append(bgr_full[int(h * 0.70):h, 0:int(w * 0.30)])
    # å³ä¸‹è§’ï¼ˆé˜²æ¨¡æ¿å˜åŒ–ï¼‰
    crops.append(bgr_full[int(h * 0.55):h, int(w * 0.55):w])

    candidates = [bgr_full] + crops
    scales = [1.0, 2.0, 3.0]
    rotations = [None, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE]

    for img in candidates:
        if img is None or img.size == 0:
            continue

        for sc in scales:
            if sc != 1.0:
                img2 = cv2.resize(img, None, fx=sc, fy=sc, interpolation=cv2.INTER_CUBIC)
            else:
                img2 = img

            # ç›´æ¥è¯†åˆ«
            got = try_decode(img2)
            if got:
                return [got]

            # é˜ˆå€¼å¢å¼ºåå†è¯†åˆ«
            gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (3, 3), 0)
            thr = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY, 31, 5
            )
            thr_bgr = cv2.cvtColor(thr, cv2.COLOR_GRAY2BGR)
            got = try_decode(thr_bgr)
            if got:
                return [got]

            # æ—‹è½¬åè¯†åˆ«ï¼ˆéƒ¨åˆ†äºŒç»´ç æ–¹å‘/é¡µæ—‹è½¬å¯¼è‡´å¤±è´¥ï¼‰
            for rot in rotations[1:]:
                rot_img = cv2.rotate(img2, rot)
                got = try_decode(rot_img)
                if got:
                    return [got]

    return []


def extract_pcid(url: str) -> Optional[str]:
    m = re.search(r"[?&]pcId=([0-9a-fA-F]+)", url)
    return m.group(1) if m else None


# =========================
# 3) URL -> ç½‘é¡µæŠ½å–ï¼ˆPlaywrightï¼‰
# =========================

def _normalize_text(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())


def extract_fields_from_html(html: str) -> Dict[str, str]:
    from bs4 import BeautifulSoup

    soup = BeautifulSoup(html, "html.parser")
    fields: Dict[str, str] = {}

    # 1) è¡¨æ ¼ï¼šä¸¤åˆ— key/value
    for table in soup.find_all("table"):
        for tr in table.find_all("tr"):
            tds = tr.find_all(["td", "th"])
            if len(tds) >= 2:
                key = _normalize_text(tds[0].get_text(" ", strip=True))
                val = _normalize_text(tds[1].get_text(" ", strip=True))
                if key and val and key not in fields:
                    fields[key] = val

    # 2) dl/dt/dd
    for dl in soup.find_all("dl"):
        dts = dl.find_all("dt")
        dds = dl.find_all("dd")
        for dt, dd in zip(dts, dds):
            key = _normalize_text(dt.get_text(" ", strip=True))
            val = _normalize_text(dd.get_text(" ", strip=True))
            if key and val and key not in fields:
                fields[key] = val

    # 3) å…œåº•ï¼šåŒ¹é… â€œé”®ï¼šå€¼â€
    text = soup.get_text("\n", strip=True)
    for line in text.split("\n"):
        line = _normalize_text(line)
        if "ï¼š" in line:
            k, v = [p.strip() for p in line.split("ï¼š", 1)]
            if k and v and len(k) <= 30 and k not in fields:
                fields[k] = v

    # è¿‡æ»¤å°‘é‡å™ªå£°ï¼ˆå¯æŒ‰å®é™…å†åŠ ï¼‰
    noise_keys = {"é¦–é¡µ", "è¿”å›", "æ‰“å°", "ä¸‹è½½", "å…³é—­"}
    for nk in list(fields.keys()):
        if nk in noise_keys:
            fields.pop(nk, None)

    return fields


def _flatten_json(obj, parent_key: str = "", sep: str = ".") -> Dict[str, str]:
    """æŠŠJSONé€’å½’æ‹å¹³ä¸º {key: value}ï¼ˆvalueç»Ÿä¸€è½¬ä¸ºå­—ç¬¦ä¸²ï¼‰ï¼Œç”¨äºå¯¼å‡ºExcelã€‚"""
    out: Dict[str, str] = {}

    def _add(k: str, v):
        if v is None:
            return
        s = str(v).strip()
        if s == "":
            return
        # é¿å…è¦†ç›–ï¼šå¦‚é‡å¤keyåˆ™è¿½åŠ åºå·
        if k in out:
            i = 2
            nk = f"{k}{sep}{i}"
            while nk in out:
                i += 1
                nk = f"{k}{sep}{i}"
            out[nk] = s
        else:
            out[k] = s

    if isinstance(obj, dict):
        for k, v in obj.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else str(k)
            if isinstance(v, (dict, list)):
                out.update(_flatten_json(v, new_key, sep=sep))
            else:
                _add(new_key, v)
    elif isinstance(obj, list):
        for idx, v in enumerate(obj):
            new_key = f"{parent_key}{sep}{idx}" if parent_key else str(idx)
            if isinstance(v, (dict, list)):
                out.update(_flatten_json(v, new_key, sep=sep))
            else:
                _add(new_key, v)
    else:
        _add(parent_key or "value", obj)

    return out


def _pick_best_json(captured: List[Tuple[str, object]], url_hint: str = "") -> Optional[object]:
    """ä»æ•è·åˆ°çš„å¤šä¸ªJSONå“åº”ä¸­æŒ‘é€‰æœ€å¯èƒ½æ˜¯â€œè¯ç…§è¯¦æƒ…â€çš„é‚£ä¸ªã€‚"""
    if not captured:
        return None

    # 1) ä¼˜å…ˆåŒ…å« pcId çš„å“åº”
    pcid = extract_pcid(url_hint) if url_hint else None
    if pcid:
        for u, j in captured:
            try:
                s = str(j)
                if pcid in s:
                    return j
            except Exception:
                pass

    # 2) å…¶æ¬¡ï¼šURLé‡Œå¸¦ detail/record/cert/sales/qr ç­‰å…³é”®è¯
    keywords = ["detail", "record", "cert", "certificate", "sales", "qr", "code", "pcid"]
    for u, j in captured:
        lu = (u or "").lower()
        if any(k in lu for k in keywords):
            return j

    # 3) å…œåº•ï¼šé€‰æ‹©â€œæ‹å¹³åå­—æ®µæœ€å¤šâ€çš„JSON
    best = None
    best_n = -1
    for u, j in captured:
        try:
            n = len(_flatten_json(j))
            if n > best_n:
                best_n = n
                best = j
        except Exception:
            pass
    return best


def scrape_cert_page(url: str, timeout_ms: int = 20000, wait_sec: float = 2.0) -> Tuple[str, Dict[str, str]]:
    """æŠ“å–è¯ç…§ç½‘é¡µã€‚

    ä¼˜å…ˆç­–ç•¥ï¼šç›‘å¬ç½‘ç»œå“åº”æŠ“åç«¯JSONï¼ˆå­—æ®µæ›´å…¨/æ›´ç¨³/æ›´å¿«ï¼‰
    å…œåº•ç­–ç•¥ï¼šæŠ“HTMLå†è§£æï¼ˆå…¼å®¹æ²¡æœ‰JSONæ¥å£æˆ–æ¥å£åŠ å¯†çš„æƒ…å†µï¼‰
    """
    from playwright.sync_api import sync_playwright

    captured_json: List[Tuple[str, object]] = []

    def on_response(resp):
        try:
            ct = (resp.headers.get("content-type") or "").lower()
            if "application/json" in ct or "text/json" in ct:
                j = resp.json()
                captured_json.append((resp.url, j))
        except Exception:
            pass

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context()
        page = context.new_page()
        page.on("response", on_response)

        # ç”¨ networkidle æ›´å®¹æ˜“ç­‰åˆ°æ¥å£è¿”å›
        try:
            page.goto(url, wait_until="networkidle", timeout=timeout_ms)
        except Exception:
            page.goto(url, wait_until="domcontentloaded", timeout=timeout_ms)

        # é¢å¤–ç­‰å¾…ä¸€ç‚¹ç‚¹ï¼Œç»™æ™šåˆ°çš„æ¥å£å“åº”æ—¶é—´
        try:
            page.wait_for_timeout(int(wait_sec * 1000))
        except Exception:
            time.sleep(wait_sec)

        title = _normalize_text(page.title())
        html = page.content()
        context.close()
        browser.close()

    # 1) JSONä¼˜å…ˆ
    best_json = _pick_best_json(captured_json, url_hint=url)
    if best_json is not None:
        fields = _flatten_json(best_json)
        # æ ‡è®°æ¥æºï¼Œä¾¿äºä½ æ ¸å¯¹
        fields["_source"] = "json"
        return title, fields

    # 2) å…œåº•ï¼šHTMLè§£æ
    fields = extract_fields_from_html(html)
    fields["_source"] = "html"
    return title, fields


# =========================
# 4) æ±‡æ€»å¯¼å‡º Excel
# =========================


@dataclass
class CertResult:
    source_file: str
    qr_url: str
    pcid: Optional[str]
    page_title: str
    fields: Dict[str, str]
    error: Optional[str] = None


# =========================
# è¾…åŠ©ï¼šæ¨æ–­åˆæ ¼è¯ç¼–å·ã€è¾“å‡ºæ–‡ä»¶å
# =========================

def _derive_cert_no(fields: Dict[str, str]) -> Optional[str]:
    r"""ä»æŠ“å–åˆ°çš„å­—æ®µä¸­æ¨æ–­â€œåˆæ ¼è¯ç¼–å·â€ï¼ˆå¸¸è§å½¢å¦‚ Bxxxx...ï¼‰ã€‚

    ä¼˜å…ˆï¼šå­—æ®µååŒ…å«â€œåˆæ ¼è¯ç¼–å·/è¯ä¹¦ç¼–å·/ç¼–å·/certNo/certificateNoâ€ç­‰
    å…œåº•ï¼šåœ¨æ‰€æœ‰ value é‡Œæ‰«æç±»ä¼¼ \bB\d{3,}\b çš„ç¼–å·
    """
    if not fields:
        return None

    # 1) ä¼˜å…ˆæŒ‰å­—æ®µåå‘½ä¸­
    key_hints = [
        "åˆæ ¼è¯ç¼–å·", "è¯ä¹¦ç¼–å·", "è¯ä¹¦ç¼–å·", "ç¼–å·", "åˆæ ¼è¯å·", "è¯ä¹¦å·",
        "certno", "cert_no", "certificateno", "certificate_no", "certificateid", "certid",
    ]

    for k, v in fields.items():
        lk = (k or "").lower()
        if any(h in k for h in key_hints[:6]) or any(h in lk for h in key_hints[6:]):
            if v:
                m = re.search(r"\bB\d{3,}\b", str(v))
                if m:
                    return m.group(0)
                # è‹¥ä¸æ˜¯Bå¼€å¤´ï¼Œä¹Ÿå…ˆè¿”å›åŸå€¼ï¼ˆåšæœ€å°æ¸…æ´—ï¼‰
                vv = str(v).strip()
                if vv:
                    return vv

    # 2) å…œåº•ï¼šæ‰«æ‰€æœ‰ value
    for v in fields.values():
        if not v:
            continue
        m = re.search(r"\bB\d{3,}\b", str(v))
        if m:
            return m.group(0)

    return None


def _safe_excel_path(out_dir: str, base_name: str) -> str:
    """ç”Ÿæˆä¸ä¼šè¦†ç›–çš„è¾“å‡ºxlsxè·¯å¾„ã€‚"""
    base = re.sub(r"[^0-9A-Za-z\u4e00-\u9fff._-]+", "_", base_name).strip("_")
    if not base:
        base = "åˆæ ¼è¯è§£æç»“æœ"
    path = os.path.join(out_dir, f"{base}.xlsx")
    if not os.path.exists(path):
        return path
    # è‹¥åŒåå·²å­˜åœ¨ï¼Œè¿½åŠ æ—¶é—´æˆ³
    ts = time.strftime("%Y%m%d_%H%M%S")
    return os.path.join(out_dir, f"{base}_{ts}.xlsx")


def process_files(file_paths: List[str]) -> List[CertResult]:
    results: List[CertResult] = []
    for fp in file_paths:
        fp_abs = os.path.abspath(fp)
        try:
            ext = os.path.splitext(fp_abs)[1].lower()

            # 1) ä¼˜å…ˆå¯¹PDFåšè§’è½é«˜DPIè¯†åˆ«ï¼›å›¾ç‰‡æ–‡ä»¶ç›´æ¥èµ°å›¾åƒè¯†åˆ«
            if ext == ".pdf":
                qr_list = decode_qr_from_pdf(fp_abs)
                # åŒæ—¶æ¸²æŸ“æ•´é¡µç”¨äºè°ƒè¯•æŸ¥çœ‹æ¸…æ™°åº¦/ä½ç½®
                img = file_to_image(fp_abs)
            else:
                img = file_to_image(fp_abs)
                qr_list = []

            # 4) å…œåº•ï¼šå¦‚æœè§’è½è¯†åˆ«æ²¡è¯»åˆ°ï¼Œå†å¯¹æ•´é¡µ/æ•´å›¾è·‘ä¸€æ¬¡å¤šç­–ç•¥è¯†åˆ«
            if not qr_list:
                qr_list = decode_qr_from_image(img)

            # è‹¥ä»æœªè¯†åˆ«åˆ°äºŒç»´ç ï¼Œæ‰è½ç›˜è°ƒè¯•å›¾ï¼Œä¾¿äºå®šä½é—®é¢˜
            if not qr_list:
                try:
                    debug_png = os.path.splitext(fp_abs)[0] + "_debug_page.png"
                    img.save(debug_png)
                    print("[DEBUG] å·²ä¿å­˜æ¸²æŸ“é¡µå›¾ï¼š", debug_png)
                except Exception:
                    pass

                if ext == ".pdf":
                    try:
                        import fitz
                        doc = fitz.open(fp_abs)
                        page = doc.load_page(0)
                        rect = page.rect
                        w, h = rect.width, rect.height
                        clip = fitz.Rect(0, h * 0.65, w * 0.35, h)
                        doc.close()

                        clip_img = _pdf_render_clip_to_image(fp_abs, clip_rect=clip, dpi=900)
                        debug_clip_png = os.path.splitext(fp_abs)[0] + "_debug_clip_bl.png"
                        clip_img.save(debug_clip_png)
                        print("[DEBUG] å·²ä¿å­˜PDFå·¦ä¸‹è§’è£å‰ªå›¾ï¼š", debug_clip_png)
                    except Exception:
                        pass

            if not qr_list:
                results.append(CertResult(fp_abs, "", None, "", {}, error="æœªè¯†åˆ«åˆ°äºŒç»´ç "))
                continue

            qr_url = qr_list[0]
            pcid = extract_pcid(qr_url) if qr_url else None

            title, fields = scrape_cert_page(qr_url)
            # è°ƒè¯•ï¼šå¯é€‰è½ç›˜å­—æ®µï¼ˆexport CERT_TOOL_DEBUG=1 å¼€å¯ï¼‰
            if DEBUG_MODE:
                try:
                    import json
                    dbg_fields = os.path.splitext(fp_abs)[0] + "_debug_fields.json"
                    with open(dbg_fields, "w", encoding="utf-8") as f:
                        json.dump(fields, f, ensure_ascii=False, indent=2)
                    print("[DEBUG] å·²ä¿å­˜æŠ“å–å­—æ®µï¼š", dbg_fields)
                except Exception:
                    pass
            results.append(CertResult(fp_abs, qr_url, pcid, title, fields, error=None))

        except Exception as e:
            results.append(CertResult(fp_abs, "", None, "", {}, error=str(e)))

    return results


def export_to_excel(results: List[CertResult], out_xlsx: str) -> None:
    import pandas as pd

    # Sheet1ï¼šä¸€è¯ä¸€è¡Œï¼ˆå®½è¡¨ï¼‰
    all_keys = set()
    for r in results:
        all_keys.update(r.fields.keys())
    all_keys = sorted(all_keys)

    wide_rows = []
    for r in results:
        row = {
            "source_file": r.source_file,
            "qr_url": r.qr_url,
            "pcId": r.pcid,
            "page_title": r.page_title,
            "error": r.error or "",
        }
        for k in all_keys:
            row[k] = r.fields.get(k, "")
        wide_rows.append(row)

    df_wide = pd.DataFrame(wide_rows)

    # Sheet2ï¼šé•¿è¡¨ï¼ˆæ›´ç¨³ï¼‰
    long_rows = []
    for r in results:
        if r.fields:
            for k, v in r.fields.items():
                long_rows.append({
                    "source_file": r.source_file,
                    "qr_url": r.qr_url,
                    "pcId": r.pcid,
                    "page_title": r.page_title,
                    "field": k,
                    "value": v,
                    "error": r.error or "",
                })
        else:
            long_rows.append({
                "source_file": r.source_file,
                "qr_url": r.qr_url,
                "pcId": r.pcid,
                "page_title": r.page_title,
                "field": "",
                "value": "",
                "error": r.error or "",
            })

    df_long = pd.DataFrame(long_rows)

    with pd.ExcelWriter(out_xlsx, engine="openpyxl") as writer:
        df_wide.to_excel(writer, index=False, sheet_name="wide")
        df_long.to_excel(writer, index=False, sheet_name="long")


# =========================
# 5) å…¥å£ï¼šå‘½ä»¤è¡Œäº¤äº’
# =========================


def parse_paths_from_input_line(line: str) -> List[str]:
    """è§£æç»ˆç«¯ä¸€è¡Œè¾“å…¥ä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ªè·¯å¾„ï¼ˆæ”¯æŒ Finder æ‹–æ‹½çš„è½¬ä¹‰/å¼•å·ï¼‰ã€‚"""
    import shlex

    line = (line or "").strip()
    if not line:
        return []

    # å…è®¸é€—å·/åˆ†å·åˆ†éš”
    chunks = [c.strip() for c in re.split(r"[;,]", line) if c.strip()]

    paths: List[str] = []
    for chunk in chunks:
        try:
            items = shlex.split(chunk)
        except Exception:
            items = [chunk]

        for it in items:
            p = os.path.expanduser(it)
            if p:
                paths.append(p)

    # å»é‡ + è§„èŒƒåŒ– + å­˜åœ¨æ€§æ£€æŸ¥
    norm: List[str] = []
    seen = set()
    for p in paths:
        ap = os.path.abspath(p)
        if ap in seen:
            continue
        seen.add(ap)
        if not os.path.exists(ap):
            print(f"[WARN] è·¯å¾„ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ï¼š{ap}")
            continue
        ext = os.path.splitext(ap)[1].lower()
        if ext not in {".pdf", ".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff", ".webp"}:
            print(f"[WARN] ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œå·²è·³è¿‡ï¼š{ap}")
            continue
        norm.append(ap)

    return norm


def interactive_drag_drop_loop():
    """äº¤äº’æ¨¡å¼ï¼šæ¯æ¬¡æ‹–å…¥ä¸€ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰åˆæ ¼è¯æ–‡ä»¶è·¯å¾„åç«‹å³å¤„ç†ã€‚

    - ç›´æ¥æŠŠæ–‡ä»¶ä» Finder æ‹–åˆ°ç»ˆç«¯çª—å£ï¼Œå›è½¦å°±å¼€å§‹å¤„ç†
    - è¾“å…¥ esc é€€å‡ºï¼ˆä¹Ÿæ”¯æŒ quit/exitï¼‰
    """
    out_dir = os.path.dirname(os.path.abspath(__file__))

    print("\nâœ… å·²å°±ç»ªã€‚è¯·æ‹–å…¥åˆæ ¼è¯æ–‡ä»¶ï¼ˆPDF/å›¾ç‰‡ï¼‰ï¼Œæˆ–è¾“å…¥ esc é€€å‡º\n")

    while True:
        try:
            line = input("æ‹–å…¥> ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n[INFO] é€€å‡ºã€‚")
            return

        if not line:
            continue

        if line.lower() in {"esc", "quit", "exit"}:
            print("[INFO] é€€å‡ºã€‚")
            return

        file_paths = parse_paths_from_input_line(line)
        if not file_paths:
            continue

        # é€ä¸ªå¤„ç†å¹¶æŒ‰â€œåˆæ ¼è¯ç¼–å·ï¼ˆBxxxxï¼‰â€å‘½åå¯¼å‡º
        for fp in file_paths:
            print(f"\nğŸ“„ æ­£åœ¨å¤„ç†ï¼š{os.path.basename(fp)}")
            results = process_files([fp])
            r0 = results[0] if results else None

            if not r0 or r0.error:
                err = r0.error if r0 else "æœªçŸ¥é”™è¯¯"
                print(f"âŒ å¤±è´¥ï¼š{err}")
                # å¤±è´¥ä¹Ÿå¯¼å‡ºä¸€ä»½ï¼ˆä¾¿äºç•™ç—•ï¼‰ï¼Œç”¨æ–‡ä»¶å+æ—¶é—´
                ts = time.strftime("%Y%m%d_%H%M%S")
                out_xlsx = _safe_excel_path(out_dir, f"å¤±è´¥_{os.path.splitext(os.path.basename(fp))[0]}_{ts}")
                export_to_excel(results, out_xlsx)
                print(f"ğŸ“Š å·²å¯¼å‡ºï¼š{os.path.basename(out_xlsx)}")
                continue

            cert_no = _derive_cert_no(r0.fields) or os.path.splitext(os.path.basename(fp))[0]
            out_xlsx = _safe_excel_path(out_dir, cert_no)
            export_to_excel(results, out_xlsx)
            print(f"âœ… æˆåŠŸï¼å·²å¯¼å‡º â†’ {os.path.basename(out_xlsx)}")


def default_output_path(script_dir: str) -> str:
    ts = time.strftime("%Y%m%d_%H%M%S")
    return os.path.join(script_dir, f"åˆæ ¼è¯è§£æç»“æœ_{ts}.xlsx")


def main():
    args = [a for a in sys.argv[1:] if a and not a.startswith("--")]

    # æœ‰å‚æ•°ï¼šæ‰¹å¤„ç†ï¼Œè¾“å‡ºä»ç”¨æ—¶é—´æˆ³æ–‡ä»¶å
    if args:
        file_paths = [os.path.abspath(os.path.expanduser(a)) for a in args]
        print(f"\nğŸ“‹ æ‰¹å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶...\n")
        results = process_files(file_paths)

        ok_n = sum(1 for r in results if not r.error)
        bad_n = len(results) - ok_n
        print(f"\nğŸ“Š å¤„ç†å®Œæˆï¼šâœ… {ok_n} æˆåŠŸï¼ŒâŒ {bad_n} å¤±è´¥")

        script_dir = os.path.dirname(os.path.abspath(__file__))
        out_xlsx = default_output_path(script_dir)
        export_to_excel(results, out_xlsx)
        print(f"\nğŸ“ å·²å¯¼å‡ºï¼š{os.path.basename(out_xlsx)}")

        if bad_n:
            print("\nâš ï¸  å¤±è´¥æ–‡ä»¶ï¼š")
            for r in results:
                if r.error:
                    print(f"  â€¢ {os.path.basename(r.source_file)} â†’ {r.error}")
        return

    # æ— å‚æ•°ï¼šäº¤äº’æ‹–æ‹½æ¨¡å¼ï¼ˆæ‹–å…¥å³å¤„ç†ï¼ŒæŒ‰Bxxxxå‘½åï¼Œç­‰å¾…ä¸‹ä¸€ä¸ªï¼‰
    interactive_drag_drop_loop()


if __name__ == "__main__":
    try:
        # è‹¥ä¸åœ¨ venvï¼Œåˆ™åˆ›å»º venv å¹¶ç”¨ venv python é‡æ–°æ‰§è¡Œ
        ensure_venv_and_rerun()

        # ä»¥ä¸‹ä»£ç åªä¼šåœ¨ venv å†…æ‰§è¡Œ
        ensure_packages_installed()
        ensure_playwright_browsers()

        main()

    except KeyboardInterrupt:
        print("\n[INFO] ç”¨æˆ·ä¸­æ–­ã€‚")
    except Exception:
        print("[ERROR] å‘ç”Ÿå¼‚å¸¸ï¼š")
        traceback.print_exc()
        print(f"[INFO] è¯¦ç»†å®‰è£…/å¯åŠ¨æ—¥å¿—ï¼š{SETUP_LOG_PATH}")
        sys.exit(1)